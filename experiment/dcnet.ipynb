{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 41 µs, total: 41 µs\n",
      "Wall time: 53.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./log/cityscapes/hrnet_w48_ocr_hrnet48.log\n",
      "World size: 4\n",
      "['--data_dir', '../../input/openseg-cityscapes-gtfine', '--checkpoints_root', './result/cityscapes/checkpoints/', '--drop_last', 'y', '--phase', 'train', '--gathered', 'n', '--loss_balance', 'y', '--log_to_file', 'n', '--pretrained', '../../input/pre-trained/hrnetv2_w48_imagenet_pretrained.pth', '--configs', 'configs/cityscapes/H_48_D_4.json', '--checkpoints_name', 'hrnet_w48_ocr_hrnet48', '--backbone', 'hrnet48', '--model_name', 'hrnet_w48_ocr', '--loss_type', 'fs_auxce_loss', '--max_iters', '40000', '--workers', '4', '--gpu', '2', '3', '4', '6', '--train_batch_size', '16', '--val_batch_size', '8', '--base_lr', '0.02', '--distributed']\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  FutureWarning,\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2023-04-26 11:38:06,955 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-04-26 11:38:06,955 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-04-26 11:38:06,955 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-04-26 11:38:06,969 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-04-26 11:38:06,969 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-04-26 11:38:06,984 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-04-26 11:38:06,984 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-04-26 11:38:06,984 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-04-26 11:38:06,987 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-04-26 11:38:06,987 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-04-26 11:38:06,987 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-04-26 11:38:07,000 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-04-26 11:38:07,000 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-04-26 11:38:07,003 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-04-26 11:38:07,003 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-04-26 11:38:07,005 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-04-26 11:38:07,005 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-04-26 11:38:07,005 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-04-26 11:38:07,021 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-04-26 11:38:07,021 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-04-26 11:38:07,890 INFO    [module_helper.py, 140] Loading pretrained model:../../input/pre-trained/hrnetv2_w48_imagenet_pretrained.pth\n",
      "2023-04-26 11:38:07,908 INFO    [module_helper.py, 140] Loading pretrained model:../../input/pre-trained/hrnetv2_w48_imagenet_pretrained.pth\n",
      "2023-04-26 11:38:07,932 INFO    [module_helper.py, 140] Loading pretrained model:../../input/pre-trained/hrnetv2_w48_imagenet_pretrained.pth\n",
      "2023-04-26 11:38:07,938 INFO    [module_helper.py, 140] Loading pretrained model:../../input/pre-trained/hrnetv2_w48_imagenet_pretrained.pth\n",
      "2023-04-26 11:38:08,195 INFO    [module_helper.py, 156] Missing keys: []\n",
      "2023-04-26 11:38:08,212 INFO    [module_helper.py, 156] Missing keys: []\n",
      "2023-04-26 11:38:08,213 INFO    [module_helper.py, 156] Missing keys: []\n",
      "2023-04-26 11:38:08,214 INFO    [module_helper.py, 156] Missing keys: []\n",
      "2023-04-26 11:38:13,452 INFO    [trainer.py, 78] Params Group Method: None\n",
      "2023-04-26 11:38:13,455 INFO    [trainer.py, 78] Params Group Method: None\n",
      "2023-04-26 11:38:13,456 INFO    [trainer.py, 78] Params Group Method: None\n",
      "2023-04-26 11:38:13,457 INFO    [trainer.py, 78] Params Group Method: None\n",
      "2023-04-26 11:38:13,459 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-04-26 11:38:13,460 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-04-26 11:38:13,461 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-04-26 11:38:13,461 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-04-26 11:38:13,462 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-04-26 11:38:13,463 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-04-26 11:38:13,464 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-04-26 11:38:13,464 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-04-26 11:38:13,500 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-04-26 11:38:13,501 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-04-26 11:38:13,501 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-04-26 11:38:13,502 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-04-26 11:38:13,507 INFO    [loss_manager.py, 64] use loss: fs_auxce_loss.\n",
      "2023-04-26 11:38:13,507 INFO    [loss_manager.py, 64] use loss: fs_auxce_loss.\n",
      "2023-04-26 11:38:13,507 INFO    [loss_manager.py, 45] use distributed loss\n",
      "2023-04-26 11:38:13,508 INFO    [loss_manager.py, 45] use distributed loss\n",
      "2023-04-26 11:38:13,508 INFO    [loss_manager.py, 64] use loss: fs_auxce_loss.\n",
      "2023-04-26 11:38:13,508 INFO    [loss_manager.py, 64] use loss: fs_auxce_loss.\n",
      "2023-04-26 11:38:13,509 INFO    [loss_manager.py, 45] use distributed loss\n",
      "2023-04-26 11:38:13,509 INFO    [loss_manager.py, 45] use distributed loss\n",
      "2023-04-26 11:38:14,950 INFO    [trainer.py, 301] 0 images processed\n",
      "\n",
      "2023-04-26 11:38:14,950 INFO    [trainer.py, 301] 0 images processed\n",
      "\n",
      "2023-04-26 11:38:14,950 INFO    [trainer.py, 301] 0 images processed\n",
      "\n",
      "2023-04-26 11:38:14,951 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-04-26 11:38:14,951 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-04-26 11:38:14,951 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-04-26 11:38:14,951 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-04-26 11:38:14,951 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-04-26 11:38:14,952 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-04-26 11:38:14,991 INFO    [trainer.py, 301] 0 images processed\n",
      "\n",
      "2023-04-26 11:38:14,992 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-04-26 11:38:14,993 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "2023-04-26 11:38:42,575 INFO    [trainer.py, 301] 10 images processed\n",
      "\n",
      "2023-04-26 11:38:42,575 INFO    [trainer.py, 301] 10 images processed\n",
      "\n",
      "2023-04-26 11:38:42,575 INFO    [trainer.py, 301] 10 images processed\n",
      "\n",
      "2023-04-26 11:38:42,575 INFO    [trainer.py, 301] 10 images processed\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !bash scripts/cityscapes/hrnet/run_h_48_d_4_ocr.sh train\n",
    "!DATA_DIR=\"../../input/openseg-cityscapes-gtfine\";CHECKPOINTS_ROOT=\"./result/cityscapes/checkpoints/\";\\\n",
    "PRETRAINED_MODEL=\"../../input/pre-trained/hrnetv2_w48_imagenet_pretrained.pth\";\\\n",
    "CONFIGS=\"configs/cityscapes/H_48_D_4.json\";\\\n",
    "BACKBONE=\"hrnet48\"; MODEL_NAME=\"hrnet_w48_ocr\";\\\n",
    "LOSS_TYPE=\"fs_auxce_loss\";\\\n",
    "CHECKPOINTS_NAME=\"${MODEL_NAME}_${BACKBONE}\";LOG_FILE=\"./log/cityscapes/${CHECKPOINTS_NAME}.log\";\\\n",
    "echo \"Logging to $LOG_FILE\";mkdir -p `dirname $LOG_FILE`;\\\n",
    "python -u main.py --data_dir ${DATA_DIR} --checkpoints_root ${CHECKPOINTS_ROOT} \\\n",
    "    --drop_last y --phase train --gathered n --loss_balance y --log_to_file n \\\n",
    "    --pretrained ${PRETRAINED_MODEL} --configs ${CONFIGS} --checkpoints_name ${CHECKPOINTS_NAME}  \\\n",
    "    --backbone ${BACKBONE} --model_name ${MODEL_NAME} --loss_type ${LOSS_TYPE}  \\\n",
    "    --max_iters 40000\\\n",
    "    --workers 4\\\n",
    "    --gpu 2 3 4 6 \\\n",
    "    --train_batch_size 16\\\n",
    "    --val_batch_size 8 \\\n",
    "    --base_lr 0.02 \\\n",
    "    --distributed \\\n",
    "    2>&1 | tee ${LOG_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./log/cityscapes/spatial_ocrnet_deepbase_resnet101_dilated8.log\n",
      "World size: 4\n",
      "['--data_dir', '../../input/openseg-cityscapes-gtfine', '--checkpoints_root', './result/cityscapes/checkpoints/', '--drop_last', 'y', '--phase', 'train', '--gathered', 'n', '--loss_balance', 'y', '--log_to_file', 'n', '--pretrained', '../../input/pre-trained/resnet101-imagenet-openseg.pth', '--configs', 'configs/cityscapes/R_101_D_8.json', '--checkpoints_name', 'spatial_ocrnet_deepbase_resnet101_dilated8', '--backbone', 'deepbase_resnet101_dilated8', '--model_name', 'spatial_ocrnet', '--loss_type', 'fs_auxce_loss', '--max_iters', '40000', '--workers', '4', '--gpu', '2', '3', '4', '6', '--train_batch_size', '8', '--val_batch_size', '4', '--distributed']\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  FutureWarning,\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2023-04-26 11:39:05,066 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-04-26 11:39:05,066 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-04-26 11:39:05,066 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-04-26 11:39:05,066 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-04-26 11:39:05,066 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-04-26 11:39:05,066 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-04-26 11:39:05,076 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-04-26 11:39:05,076 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-04-26 11:39:05,076 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-04-26 11:39:05,082 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-04-26 11:39:05,082 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-04-26 11:39:05,082 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-04-26 11:39:05,082 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-04-26 11:39:05,092 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-04-26 11:39:05,093 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-04-26 11:39:05,095 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-04-26 11:39:05,095 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-04-26 11:39:05,095 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-04-26 11:39:05,112 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-04-26 11:39:05,112 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-04-26 11:39:05,988 INFO    [module_helper.py, 128] Loading pretrained model:../../input/pre-trained/resnet101-imagenet-openseg.pth\n",
      "2023-04-26 11:39:05,994 INFO    [module_helper.py, 128] Loading pretrained model:../../input/pre-trained/resnet101-imagenet-openseg.pth\n",
      "2023-04-26 11:39:06,022 INFO    [module_helper.py, 128] Loading pretrained model:../../input/pre-trained/resnet101-imagenet-openseg.pth\n",
      "2023-04-26 11:39:06,132 INFO    [module_helper.py, 128] Loading pretrained model:../../input/pre-trained/resnet101-imagenet-openseg.pth\n",
      "2023-04-26 11:39:14,807 INFO    [trainer.py, 78] Params Group Method: None\n",
      "2023-04-26 11:39:14,808 INFO    [trainer.py, 78] Params Group Method: None\n",
      "2023-04-26 11:39:14,809 INFO    [trainer.py, 78] Params Group Method: None\n",
      "2023-04-26 11:39:14,810 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-04-26 11:39:14,810 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-04-26 11:39:14,811 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-04-26 11:39:14,811 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-04-26 11:39:14,811 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-04-26 11:39:14,812 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-04-26 11:39:14,818 INFO    [trainer.py, 78] Params Group Method: None\n",
      "2023-04-26 11:39:14,821 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-04-26 11:39:14,821 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-04-26 11:39:14,848 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-04-26 11:39:14,848 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-04-26 11:39:14,851 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-04-26 11:39:14,854 INFO    [loss_manager.py, 64] use loss: fs_auxce_loss.\n",
      "2023-04-26 11:39:14,854 INFO    [loss_manager.py, 64] use loss: fs_auxce_loss.\n",
      "2023-04-26 11:39:14,855 INFO    [loss_manager.py, 45] use distributed loss\n",
      "2023-04-26 11:39:14,855 INFO    [loss_manager.py, 45] use distributed loss\n",
      "2023-04-26 11:39:14,857 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-04-26 11:39:14,858 INFO    [loss_manager.py, 64] use loss: fs_auxce_loss.\n",
      "2023-04-26 11:39:14,858 INFO    [loss_manager.py, 45] use distributed loss\n",
      "2023-04-26 11:39:14,863 INFO    [loss_manager.py, 64] use loss: fs_auxce_loss.\n",
      "2023-04-26 11:39:14,864 INFO    [loss_manager.py, 45] use distributed loss\n",
      "2023-04-26 11:39:15,809 INFO    [trainer.py, 301] 0 images processed\n",
      "\n",
      "2023-04-26 11:39:15,809 INFO    [trainer.py, 301] 0 images processed\n",
      "\n",
      "2023-04-26 11:39:15,812 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-04-26 11:39:15,812 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-04-26 11:39:15,813 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-04-26 11:39:15,813 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-04-26 11:39:15,817 INFO    [trainer.py, 301] 0 images processed\n",
      "\n",
      "2023-04-26 11:39:15,818 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-04-26 11:39:15,818 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-04-26 11:39:15,827 INFO    [trainer.py, 301] 0 images processed\n",
      "\n",
      "2023-04-26 11:39:15,828 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-04-26 11:39:15,828 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# !bash scripts/cityscapes/ocrnet/dc_run_r_101_d_8_ocrnet_train.sh train\n",
    "!DATA_DIR=\"../../input/openseg-cityscapes-gtfine\";CHECKPOINTS_ROOT=\"./result/cityscapes/checkpoints/\";\\\n",
    "PRETRAINED_MODEL=\"../../input/pre-trained/resnet101-imagenet-openseg.pth\";\\\n",
    "CONFIGS=\"configs/cityscapes/DC_R_101_D_8.json\";\\\n",
    "BACKBONE=\"deepbase_resnet101_dilated8\"; MODEL_NAME=\"spatial_ocrnet_dc\";\\\n",
    "LOSS_TYPE=\"fs_auxce_loss_dc\";\\\n",
    "CHECKPOINTS_NAME=\"${MODEL_NAME}_${BACKBONE}\";LOG_FILE=\"./log/cityscapes/${CHECKPOINTS_NAME}.log\";\\\n",
    "echo \"Logging to $LOG_FILE\";mkdir -p `dirname $LOG_FILE`;\\\n",
    "python -u main.py --data_dir ${DATA_DIR} --checkpoints_root ${CHECKPOINTS_ROOT} \\\n",
    "    --drop_last y --phase train --gathered n --loss_balance y --log_to_file n \\\n",
    "    --pretrained ${PRETRAINED_MODEL} --configs ${CONFIGS} --checkpoints_name ${CHECKPOINTS_NAME}  \\\n",
    "    --backbone ${BACKBONE} --model_name ${MODEL_NAME} --loss_type ${LOSS_TYPE}  \\\n",
    "    --max_iters 40000\\\n",
    "    --workers 4\\\n",
    "    --gpu 2 3 4 6 \\\n",
    "    --train_batch_size 8\\\n",
    "    --val_batch_size 4 \\\n",
    "    --distributed \\\n",
    "    2>&1 | tee ${LOG_FILE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42a4ea106d429adb85b92cbf5fe6fad5ad2431a3e82cdef4435b2cc92f522609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
