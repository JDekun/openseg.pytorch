{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62 µs, sys: 7 µs, total: 69 µs\n",
      "Wall time: 76.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./experiment/log/cityscapes/resnet_fcn_asp_3_deepbase_resnet101_dilated8_2023-05-04_22-38-24.log\n",
      "World size: 4\n",
      "['--configs', 'configs/cityscapes/R_101_D_8.json', '--drop_last', 'y', '--phase', 'train', '--gathered', 'n', '--loss_balance', 'y', '--log_to_file', 'n', '--backbone', 'deepbase_resnet101_dilated8', '--model_name', 'resnet_fcn_asp_3', '--gpu', '3', '4', '5', '6', '--train_batch_size', '8', '--val_batch_size', '4', '--data_dir', '../../input/openseg-cityscapes-gtfine', '--loss_type', 'fs_auxce_loss', '--max_iters', '40000', '--checkpoints_name', 'resnet_fcn_asp_3_deepbase_resnet101_dilated8_2023-05-04_22-38-24', '--pretrained', '../../input/pre-trained/resnet101-imagenet-openseg.pth', '--distributed']\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  FutureWarning,\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "2023-05-04 22:38:30,423 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-05-04 22:38:30,423 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-05-04 22:38:30,423 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-05-04 22:38:30,438 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-05-04 22:38:30,438 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-05-04 22:38:30,439 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-05-04 22:38:30,440 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-05-04 22:38:30,440 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-05-04 22:38:30,442 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-05-04 22:38:30,442 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-05-04 22:38:30,442 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-05-04 22:38:30,457 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-05-04 22:38:30,457 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-05-04 22:38:30,459 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-05-04 22:38:30,459 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-05-04 22:38:30,472 INFO    [offset_helper.py, 54] engery/max-distance: 5 engery/min-distance: 0\n",
      "2023-05-04 22:38:30,472 INFO    [offset_helper.py, 61] direction/num_classes: 8 scale: 1\n",
      "2023-05-04 22:38:30,472 INFO    [offset_helper.py, 66] c4 align axis: False\n",
      "2023-05-04 22:38:30,489 INFO    [module_runner.py, 44] BN Type is torchsyncbn.\n",
      "2023-05-04 22:38:30,489 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator\n",
      "2023-05-04 22:38:31,379 INFO    [module_helper.py, 128] Loading pretrained model:../../input/pre-trained/resnet101-imagenet-openseg.pth\n",
      "2023-05-04 22:38:31,381 INFO    [module_helper.py, 128] Loading pretrained model:../../input/pre-trained/resnet101-imagenet-openseg.pth\n",
      "2023-05-04 22:38:31,390 INFO    [module_helper.py, 128] Loading pretrained model:../../input/pre-trained/resnet101-imagenet-openseg.pth\n",
      "2023-05-04 22:38:31,422 INFO    [module_helper.py, 128] Loading pretrained model:../../input/pre-trained/resnet101-imagenet-openseg.pth\n",
      "2023-05-04 22:38:40,997 INFO    [trainer.py, 80] Params Group Method: None\n",
      "2023-05-04 22:38:40,997 INFO    [trainer.py, 80] Params Group Method: None\n",
      "2023-05-04 22:38:40,999 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "DistributedDataParallel(\n",
      "  (module): RES_FCN_ASP_3(\n",
      "    (backbone): DilatedResnetBackbone(\n",
      "      (resinit): Sequential(\n",
      "        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU()\n",
      "        (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu3): ReLU()\n",
      "      )\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (6): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (7): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (8): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (9): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (10): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (11): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (12): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (13): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (14): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (15): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (16): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (17): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (18): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (19): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (20): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (21): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (22): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU()\n",
      "          (relu_in): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fcn_asp_head): FCN_ASP_3(\n",
      "      (fcn): Sequential(\n",
      "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Sequential(\n",
      "          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
      "        (1): Sequential(\n",
      "          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
      "        (1): Sequential(\n",
      "          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv5): Sequential(\n",
      "        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36))\n",
      "        (1): Sequential(\n",
      "          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_bn_dropout): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Sequential(\n",
      "          (0): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (2): Dropout2d(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (head): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (dsn_head): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): Sequential(\n",
      "        (0): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (2): Dropout2d(p=0.1, inplace=False)\n",
      "      (3): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2023-05-04 22:38:41,000 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-05-04 22:38:41,000 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-05-04 22:38:41,000 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-05-04 22:38:41,000 INFO    [trainer.py, 80] Params Group Method: None\n",
      "2023-05-04 22:38:41,003 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-05-04 22:38:41,003 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-05-04 22:38:41,006 INFO    [trainer.py, 80] Params Group Method: None\n",
      "2023-05-04 22:38:41,010 INFO    [optim_scheduler.py, 90] Use lambda_poly policy with default power 0.9\n",
      "2023-05-04 22:38:41,010 INFO    [data_loader.py, 131] use the DefaultLoader for train...\n",
      "2023-05-04 22:38:41,041 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-05-04 22:38:41,041 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-05-04 22:38:41,041 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-05-04 22:38:41,047 INFO    [loss_manager.py, 66] use loss: fs_auxce_loss.\n",
      "2023-05-04 22:38:41,047 INFO    [loss_manager.py, 66] use loss: fs_auxce_loss.\n",
      "2023-05-04 22:38:41,047 INFO    [loss_manager.py, 66] use loss: fs_auxce_loss.\n",
      "2023-05-04 22:38:41,048 INFO    [loss_manager.py, 47] use distributed loss\n",
      "2023-05-04 22:38:41,048 INFO    [loss_manager.py, 47] use distributed loss\n",
      "2023-05-04 22:38:41,048 INFO    [loss_manager.py, 47] use distributed loss\n",
      "2023-05-04 22:38:41,063 INFO    [data_loader.py, 164] use DefaultLoader for val ...\n",
      "2023-05-04 22:38:41,074 INFO    [loss_manager.py, 66] use loss: fs_auxce_loss.\n",
      "2023-05-04 22:38:41,076 INFO    [loss_manager.py, 47] use distributed loss\n",
      "2023-05-04 22:38:42,821 INFO    [trainer.py, 303] 0 images processed\n",
      "\n",
      "2023-05-04 22:38:42,824 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-05-04 22:38:42,824 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-05-04 22:38:42,827 INFO    [trainer.py, 303] 0 images processed\n",
      "\n",
      "2023-05-04 22:38:42,827 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-05-04 22:38:42,827 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-05-04 22:38:42,830 INFO    [trainer.py, 303] 0 images processed\n",
      "\n",
      "2023-05-04 22:38:42,831 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-05-04 22:38:42,831 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "2023-05-04 22:38:42,832 INFO    [trainer.py, 303] 0 images processed\n",
      "\n",
      "2023-05-04 22:38:42,832 INFO    [data_helper.py, 123] Input keys: ['img']\n",
      "2023-05-04 22:38:42,832 INFO    [data_helper.py, 124] Target keys: ['labelmap']\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "2023-05-04 22:39:00,998 INFO    [trainer.py, 303] 10 images processed\n",
      "\n",
      "2023-05-04 22:39:00,998 INFO    [trainer.py, 303] 10 images processed\n",
      "\n",
      "2023-05-04 22:39:00,998 INFO    [trainer.py, 303] 10 images processed\n",
      "\n",
      "2023-05-04 22:39:00,998 INFO    [trainer.py, 303] 10 images processed\n",
      "\n",
      "2023-05-04 22:39:14,501 INFO    [trainer.py, 303] 20 images processed\n",
      "\n",
      "2023-05-04 22:39:14,501 INFO    [trainer.py, 303] 20 images processed\n",
      "\n",
      "2023-05-04 22:39:14,501 INFO    [trainer.py, 303] 20 images processed\n",
      "\n",
      "2023-05-04 22:39:14,501 INFO    [trainer.py, 303] 20 images processed\n",
      "\n",
      "2023-05-04 22:39:25,840 INFO    [trainer.py, 303] 30 images processed\n",
      "\n",
      "2023-05-04 22:39:25,840 INFO    [trainer.py, 303] 30 images processed\n",
      "\n",
      "2023-05-04 22:39:25,840 INFO    [trainer.py, 303] 30 images processed\n",
      "\n",
      "2023-05-04 22:39:25,840 INFO    [trainer.py, 303] 30 images processed\n",
      "\n",
      "2023-05-04 22:39:37,239 INFO    [trainer.py, 303] 40 images processed\n",
      "\n",
      "2023-05-04 22:39:37,239 INFO    [trainer.py, 303] 40 images processed\n",
      "\n",
      "2023-05-04 22:39:37,240 INFO    [trainer.py, 303] 40 images processed\n",
      "\n",
      "2023-05-04 22:39:37,239 INFO    [trainer.py, 303] 40 images processed\n",
      "\n",
      "2023-05-04 22:39:48,559 INFO    [trainer.py, 303] 50 images processed\n",
      "\n",
      "2023-05-04 22:39:48,559 INFO    [trainer.py, 303] 50 images processed\n",
      "\n",
      "2023-05-04 22:39:48,559 INFO    [trainer.py, 303] 50 images processed\n",
      "\n",
      "2023-05-04 22:39:48,560 INFO    [trainer.py, 303] 50 images processed\n",
      "\n",
      "2023-05-04 22:39:59,927 INFO    [trainer.py, 303] 60 images processed\n",
      "\n",
      "2023-05-04 22:39:59,927 INFO    [trainer.py, 303] 60 images processed\n",
      "\n",
      "2023-05-04 22:39:59,927 INFO    [trainer.py, 303] 60 images processed\n",
      "\n",
      "2023-05-04 22:39:59,927 INFO    [trainer.py, 303] 60 images processed\n",
      "\n",
      "2023-05-04 22:40:11,304 INFO    [trainer.py, 303] 70 images processed\n",
      "\n",
      "2023-05-04 22:40:11,305 INFO    [trainer.py, 303] 70 images processed\n",
      "\n",
      "2023-05-04 22:40:11,305 INFO    [trainer.py, 303] 70 images processed\n",
      "\n",
      "2023-05-04 22:40:11,305 INFO    [trainer.py, 303] 70 images processed\n",
      "\n",
      "2023-05-04 22:40:23,226 INFO    [trainer.py, 303] 80 images processed\n",
      "\n",
      "2023-05-04 22:40:23,226 INFO    [trainer.py, 303] 80 images processed\n",
      "\n",
      "2023-05-04 22:40:23,226 INFO    [trainer.py, 303] 80 images processed\n",
      "\n",
      "2023-05-04 22:40:23,226 INFO    [trainer.py, 303] 80 images processed\n",
      "\n",
      "2023-05-04 22:40:34,621 INFO    [trainer.py, 303] 90 images processed\n",
      "\n",
      "2023-05-04 22:40:34,621 INFO    [trainer.py, 303] 90 images processed\n",
      "\n",
      "2023-05-04 22:40:34,621 INFO    [trainer.py, 303] 90 images processed\n",
      "\n",
      "2023-05-04 22:40:34,621 INFO    [trainer.py, 303] 90 images processed\n",
      "\n",
      "2023-05-04 22:40:45,913 INFO    [trainer.py, 303] 100 images processed\n",
      "\n",
      "2023-05-04 22:40:45,913 INFO    [trainer.py, 303] 100 images processed\n",
      "\n",
      "2023-05-04 22:40:45,913 INFO    [trainer.py, 303] 100 images processed\n",
      "\n",
      "2023-05-04 22:40:45,913 INFO    [trainer.py, 303] 100 images processed\n",
      "\n",
      "2023-05-04 22:40:57,299 INFO    [trainer.py, 303] 110 images processed\n",
      "\n",
      "2023-05-04 22:40:57,299 INFO    [trainer.py, 303] 110 images processed\n",
      "\n",
      "2023-05-04 22:40:57,299 INFO    [trainer.py, 303] 110 images processed\n",
      "\n",
      "2023-05-04 22:40:57,299 INFO    [trainer.py, 303] 110 images processed\n",
      "\n",
      "2023-05-04 22:41:08,794 INFO    [trainer.py, 303] 120 images processed\n",
      "\n",
      "2023-05-04 22:41:08,794 INFO    [trainer.py, 303] 120 images processed\n",
      "\n",
      "2023-05-04 22:41:08,794 INFO    [trainer.py, 303] 120 images processed\n",
      "\n",
      "2023-05-04 22:41:08,794 INFO    [trainer.py, 303] 120 images processed\n",
      "\n",
      "2023-05-04 22:41:14,649 INFO    [base.py, 84] Performance 0.0 -> 0.019213993399188455\n",
      "2023-05-04 22:41:17,568 INFO    [trainer.py, 405] Test Time 153.382s, (1.227)\tLoss 4.06771903\n",
      "\n",
      "2023-05-04 22:41:17,569 INFO    [base.py, 33] Result for seg\n",
      "2023-05-04 22:41:17,570 INFO    [base.py, 49] Mean IOU: 0.019213993399188455\n",
      "\n",
      "2023-05-04 22:41:17,570 INFO    [base.py, 50] Pixel ACC: 0.18902878631054515\n",
      "\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/zk/anaconda3/envs/temp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "2023-05-04 22:41:28,306 INFO    Reducer buckets have been rebuilt in this iteration.\n",
      "2023-05-04 22:41:28,306 INFO    Reducer buckets have been rebuilt in this iteration.\n",
      "2023-05-04 22:41:28,333 INFO    Reducer buckets have been rebuilt in this iteration.\n",
      "2023-05-04 22:41:28,338 INFO    Reducer buckets have been rebuilt in this iteration.\n",
      "2023-05-04 22:41:47,119 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 10\tTime 29.545s / 10iters, (2.954)\tForward Time 8.242s / 10iters, (0.824)\tBackward Time 20.438s / 10iters, (2.044)\tLoss Time 0.074s / 10iters, (0.007)\tData load 0.791s / 10iters, (0.079059)\n",
      "Learning rate = [0.00999797497721687, 0.00999797497721687]\tLoss = 1.55227375 (ave = 2.69256175)\n",
      "\n",
      "2023-05-04 22:42:07,696 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 20\tTime 20.577s / 10iters, (2.058)\tForward Time 5.136s / 10iters, (0.514)\tBackward Time 15.288s / 10iters, (1.529)\tLoss Time 0.072s / 10iters, (0.007)\tData load 0.081s / 10iters, (0.008127)\n",
      "Learning rate = [0.009995724898451063, 0.009995724898451063]\tLoss = 1.67119408 (ave = 2.29223545)\n",
      "\n",
      "2023-05-04 22:42:28,153 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 30\tTime 20.457s / 10iters, (2.046)\tForward Time 5.181s / 10iters, (0.518)\tBackward Time 15.111s / 10iters, (1.511)\tLoss Time 0.079s / 10iters, (0.008)\tData load 0.086s / 10iters, (0.008625)\n",
      "Learning rate = [0.00999347476340585, 0.00999347476340585]\tLoss = 2.72402334 (ave = 1.64512593)\n",
      "\n",
      "2023-05-04 22:42:48,638 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 40\tTime 20.485s / 10iters, (2.048)\tForward Time 5.131s / 10iters, (0.513)\tBackward Time 15.203s / 10iters, (1.520)\tLoss Time 0.074s / 10iters, (0.007)\tData load 0.076s / 10iters, (0.007589)\n",
      "Learning rate = [0.00999122457206574, 0.00999122457206574]\tLoss = 1.08237350 (ave = 1.57222713)\n",
      "\n",
      "2023-05-04 22:43:09,260 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 50\tTime 20.622s / 10iters, (2.062)\tForward Time 5.114s / 10iters, (0.511)\tBackward Time 15.354s / 10iters, (1.535)\tLoss Time 0.077s / 10iters, (0.008)\tData load 0.078s / 10iters, (0.007754)\n",
      "Learning rate = [0.00998897432441524, 0.00998897432441524]\tLoss = 1.76230419 (ave = 1.42973370)\n",
      "\n",
      "2023-05-04 22:43:29,720 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 60\tTime 20.460s / 10iters, (2.046)\tForward Time 5.032s / 10iters, (0.503)\tBackward Time 15.269s / 10iters, (1.527)\tLoss Time 0.075s / 10iters, (0.008)\tData load 0.084s / 10iters, (0.008365)\n",
      "Learning rate = [0.009986724020438846, 0.009986724020438846]\tLoss = 1.00719810 (ave = 1.23882254)\n",
      "\n",
      "2023-05-04 22:43:50,280 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 70\tTime 20.560s / 10iters, (2.056)\tForward Time 5.153s / 10iters, (0.515)\tBackward Time 15.254s / 10iters, (1.525)\tLoss Time 0.070s / 10iters, (0.007)\tData load 0.084s / 10iters, (0.008359)\n",
      "Learning rate = [0.009984473660121045, 0.009984473660121045]\tLoss = 1.15925992 (ave = 1.29067658)\n",
      "\n",
      "2023-05-04 22:44:10,568 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 80\tTime 20.288s / 10iters, (2.029)\tForward Time 5.034s / 10iters, (0.503)\tBackward Time 15.101s / 10iters, (1.510)\tLoss Time 0.071s / 10iters, (0.007)\tData load 0.082s / 10iters, (0.008229)\n",
      "Learning rate = [0.009982223243446315, 0.009982223243446315]\tLoss = 1.45696080 (ave = 1.14778917)\n",
      "\n",
      "2023-05-04 22:44:31,154 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 90\tTime 20.586s / 10iters, (2.059)\tForward Time 5.155s / 10iters, (0.516)\tBackward Time 15.273s / 10iters, (1.527)\tLoss Time 0.072s / 10iters, (0.007)\tData load 0.086s / 10iters, (0.008615)\n",
      "Learning rate = [0.009979972770399127, 0.009979972770399127]\tLoss = 0.97855175 (ave = 1.22074301)\n",
      "\n",
      "2023-05-04 22:44:51,621 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 100\tTime 20.467s / 10iters, (2.047)\tForward Time 5.145s / 10iters, (0.515)\tBackward Time 15.169s / 10iters, (1.517)\tLoss Time 0.079s / 10iters, (0.008)\tData load 0.074s / 10iters, (0.007429)\n",
      "Learning rate = [0.009977722240963943, 0.009977722240963943]\tLoss = 1.06718946 (ave = 0.87197689)\n",
      "\n",
      "2023-05-04 22:45:12,059 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 110\tTime 20.439s / 10iters, (2.044)\tForward Time 5.198s / 10iters, (0.520)\tBackward Time 15.084s / 10iters, (1.508)\tLoss Time 0.076s / 10iters, (0.008)\tData load 0.080s / 10iters, (0.008030)\n",
      "Learning rate = [0.00997547165512522, 0.00997547165512522]\tLoss = 1.00716841 (ave = 0.89680769)\n",
      "\n",
      "2023-05-04 22:45:32,305 INFO    [trainer.py, 252] Train Epoch: 0\tTrain Iteration: 120\tTime 20.246s / 10iters, (2.025)\tForward Time 5.054s / 10iters, (0.505)\tBackward Time 15.041s / 10iters, (1.504)\tLoss Time 0.073s / 10iters, (0.007)\tData load 0.077s / 10iters, (0.007732)\n",
      "Learning rate = [0.009973221012867402, 0.009973221012867402]\tLoss = 0.48388937 (ave = 0.77273842)\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bash experiment/mep.sh train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42a4ea106d429adb85b92cbf5fe6fad5ad2431a3e82cdef4435b2cc92f522609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
